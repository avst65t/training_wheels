{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958d35c1",
   "metadata": {},
   "source": [
    "- Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5408fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, tempfile, librosa, pyaudio\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from scipy import signal\n",
    "import keras.utils as image\n",
    "from pydub import AudioSegment\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG19\n",
    "# import sounddevice as sd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba45dc61",
   "metadata": {},
   "source": [
    "- Time taken to load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86504c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "model = tf.keras.models.load_model('ann_mobilenetv2_1_sec.h5')\n",
    "base_model = MobileNetV2(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "if not os.path.exists(os.path.join('temp')):\n",
    "    os.mkdir(os.path.join('temp'))\n",
    "\n",
    "end = time.time()\n",
    "print('load the model',f'>>>>{round((end-start),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89bca4d",
   "metadata": {},
   "source": [
    "- Load ground truth labels from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13da526",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = pd.read_csv(r'actual_labels.csv')\n",
    "asd =fd['Actual']\n",
    "asd =asd.to_list()\n",
    "asd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de89c217",
   "metadata": {},
   "source": [
    "- This function calculates and returns time for operations like:\n",
    "\n",
    "    - convert audio to spectrogram and save it\n",
    "    - load the saved image from disk\n",
    "    - extract features from the image using mobilenetv2\n",
    "    - Prediction by the model\n",
    "    - total time taken for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03e145f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(aud_data, sr,count):\n",
    "    print(f'>>>>>>>>>>>>>>>>> for the {count} chunk >>>>>>>>>>>>>>>>>')\n",
    "\n",
    "#     play the audio\n",
    "#     sd.play(aud_data, sr)\n",
    "#     sd.wait()\n",
    "#     time.sleep(1.5)\n",
    "\n",
    "    s = time.time()\n",
    "    \n",
    "    #convert the audio sample into the spectogram\n",
    "    start = time.time()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    ms = librosa.feature.melspectrogram(y=aud_data, sr=8000)\n",
    "    log_ms = librosa.power_to_db(ms, ref=np.max)\n",
    "    librosa.display.specshow(log_ms, sr=RATE)\n",
    "    fig.savefig(f'temp/temp.png')\n",
    "    end = time.time()\n",
    "    first =round((end-start),4)\n",
    "    print('To convert audio sample into the spectogram',f'>>>>{round((end-start),4)}')\n",
    "    \n",
    "    #convert the image into the array\n",
    "    start = time.time()\n",
    "    images = image.img_to_array(image.load_img('temp/temp.png', target_size=(224, 224)))\n",
    "    os.remove('temp/temp.png')\n",
    "    x = np.expand_dims(images, axis=0)\n",
    "    end = time.time()\n",
    "    second =round((end-start),4)\n",
    "    print('To convert spectogram into the array',f'>>>>{round((end-start),4)}')\n",
    "    \n",
    "    #extract the feature from the image using mobilnetv2\n",
    "    start = time.time()\n",
    "    x = preprocess_input(np.array(x))\n",
    "    y = base_model.predict(x, verbose=False)\n",
    "    end = time.time()\n",
    "    Third =round((end-start),4)\n",
    "    print('extract the feature from array',f'>>>>{round((end-start),4)}')\n",
    "    \n",
    "    #Here we predict the result from model\n",
    "    start = time.time()\n",
    "    predictions = model.predict(y, verbose=False)\n",
    "    res = np.argmax(predictions)\n",
    "    print(class_labels[res])\n",
    "    end = time.time()\n",
    "    fourth =round((end-start),4)\n",
    "    print('model prediction timing',f'>>>>{round((end-start),4)}')\n",
    "    \n",
    "    plt.close('all')\n",
    "    e = time.time()\n",
    "    fifth =round((e-s),4)\n",
    "    print('time taken by the whole code',f'>>>>{round((e-s),4)}')\n",
    "    \n",
    "    return class_labels[res],first,second,Third,fourth,fifth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1448798",
   "metadata": {},
   "source": [
    "- load the audio file\n",
    "- take 2 second chunk and get the time intervals for operations\n",
    "- append the results in a list\n",
    "- repeat step 2 and 3 till the end of audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfbf8d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_labels = ['IVR', 'Music', 'Speech']\n",
    "audio_file=r'test_1sec.wav'\n",
    "RATE = 8000\n",
    "lst =[]\n",
    "count =1\n",
    "c=0\n",
    "time_chunk=2\n",
    "\n",
    "audio_data, sr = librosa.load(audio_file,sr =RATE)\n",
    "while True: \n",
    "    r = RATE * time_chunk\n",
    "    if len(audio_data)>r:\n",
    "        audio_data1 = audio_data[:r]\n",
    "        audio_data =audio_data[r:]\n",
    "        res,first,second,Third,fourth,fifth =process_audio(audio_data1, sr,count)\n",
    "        lst.append([asd[c],res,first,second,Third,fourth,fifth])\n",
    "        count+=1\n",
    "        c+=1\n",
    "    else:\n",
    "        res,first,second,Third,fourth,fifth =process_audio(audio_data, sr,count)\n",
    "        lst.append([asd[c],res,first,second,Third,fourth,fifth])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25028f6",
   "metadata": {},
   "source": [
    "- convert the list to dataframe with column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dc4e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(lst,columns =['Actual','predict','audio to spectogram','spectogram to array','extract the feature','model prediction timing','whole time-taken'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cceeca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941fdd32",
   "metadata": {},
   "source": [
    "- export the dataframe results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2587f135",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('mix_1sec.csv',index =False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
