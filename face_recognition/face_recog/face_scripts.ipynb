{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "537c2d01",
   "metadata": {},
   "source": [
    "### Color to Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wRl__7ZTOFzV",
   "metadata": {
    "id": "wRl__7ZTOFzV"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import streamlit as st\n",
    "\n",
    "def video_to_grayscale(vid_path):\n",
    "    # open the video\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "\n",
    "    # create a writer object to save the grayscale video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter('grayscale_video.mp4', fourcc, cap.get(cv2.CAP_PROP_FPS), \n",
    "                          (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))), \n",
    "                          isColor=False)\n",
    "\n",
    "    # loop over frames in the video\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # convert frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # write grayscale frame to writer object\n",
    "        out.write(gray)\n",
    "\n",
    "    # release resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# streamlit app\n",
    "st.title('Video to Grayscale')\n",
    "vid_file = st.file_uploader('Upload a video file', type=['mp4'])\n",
    "\n",
    "if vid_file is not None:\n",
    "    # display uploaded video\n",
    "    st.video(vid_file)\n",
    "\n",
    "    # convert video to grayscale and save\n",
    "    video_to_grayscale(vid_file.name)\n",
    "\n",
    "    # display link to download grayscale video\n",
    "    st.markdown('Download grayscale video [here](./grayscale_video.mp4)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d095cc8",
   "metadata": {
    "id": "8d095cc8"
   },
   "source": [
    "### YuNET face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5032e5",
   "metadata": {
    "id": "7d5032e5",
    "outputId": "a7063dde-71ea-4275-f9e8-fa9ef01f65c7"
   },
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "detector = cv2.FaceDetectorYN.create(\"yunet_22mar.onnx\", \"\", (320, 320))\n",
    "i=0\n",
    "j=0\n",
    "n_images=50\n",
    "k=int(n_images/10)\n",
    "while True:\n",
    "    ret, collection_frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width, _ = collection_frame.shape\n",
    "    detector.setInputSize((width, height))\n",
    "    _, faces = detector.detect(collection_frame)\n",
    "    if faces is not None:\n",
    "        for face in faces:\n",
    "            if i%10==0:\n",
    "                j+=1\n",
    "            x,y,w,h = list(map(int, face[:4]))\n",
    "            cv2.putText(collection_frame, f'Images Captured: {j}/{k}',(30,30),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255, 127, 0),1,cv2.LINE_AA)\n",
    "            cv2.rectangle(collection_frame, (x,y), (x+w,y+h), (255,0,0), 2)   \n",
    "    \n",
    "    i+=1\n",
    "    cv2.imshow('img', collection_frame)\n",
    "    if j==n_images:\n",
    "        break\n",
    "    if cv2.waitKey(1)==27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a762572",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "detector = cv2.FaceDetectorYN.create(\"yunet_22mar.onnx\", \"\", (320, 320))\n",
    "i=0\n",
    "n_images=500\n",
    "id=input('id: ')\n",
    "path='dataset/'+id\n",
    "if not os.path.isdir(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "while True:\n",
    "    ret, collection_frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width, _ = collection_frame.shape\n",
    "    detector.setInputSize((width, height))\n",
    "    _, faces = detector.detect(collection_frame)\n",
    "    if faces is not None:\n",
    "        for face in faces:\n",
    "            x,y,w,h = list(map(int, face[:4]))\n",
    "            cv2.putText(collection_frame, f'Images Captured: {i}/{n_images}',(30,30),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255, 127, 0),1,cv2.LINE_AA)\n",
    "            cv2.imwrite(path + '/' +str(i) + \".jpg\", collection_frame)\n",
    "            cv2.rectangle(collection_frame, (x,y), (x+w,y+h), (255,0,0), 2)   \n",
    "            i+=1\n",
    "\n",
    "    cv2.imshow('img', collection_frame)\n",
    "    if i==n_images:\n",
    "        break\n",
    "    if cv2.waitKey(1)==27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd469477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/GPU:0'):\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "detector = cv2.FaceDetectorYN.create(\"yunet_22mar.onnx\", \"\", (320, 320))\n",
    "model = load_model('emp_face_vgg_model.h5', compile=False)\n",
    "with open(\"emp-face-labels.pickle\", 'rb') as f:\n",
    "    og_labels = pickle.load(f)\n",
    "    labels = {key:value for key,value in og_labels.items()}\n",
    "\n",
    "stream = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    (grabbed, frame) = stream.read()\n",
    "    height, width, _ = frame.shape\n",
    "    detector.setInputSize((width, height))\n",
    "    _, faces = detector.detect(frame)\n",
    "    if faces is not None:    \n",
    "        for face in faces:\n",
    "            x,y,w,h = list(map(int, face[:4]))\n",
    "\n",
    "            color = (255, 127, 0)\n",
    "            stroke = 2\n",
    "            cv2.rectangle(frame, (x,y), (x+w,y+h), color, stroke)\n",
    "\n",
    "            roi_rgb = frame[y:y+h, x:x+w]\n",
    "            size = (image_width, image_height)\n",
    "            resized_image = cv2.resize(roi_rgb, size)\n",
    "            image_array = np.array(resized_image, \"uint8\")\n",
    "            img = image_array.reshape(1,image_width,image_height,3) \n",
    "            img = img.astype('float32')\n",
    "            img /= 255\n",
    "            predicted_prob = model.predict(img)\n",
    "\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            name = labels[predicted_prob[0].argmax()]\n",
    "            color = (255, 0, 255)\n",
    "            stroke = 2\n",
    "            cv2.putText(frame, f'({name})', (x,y-8), font, 1, color, stroke, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Image\", frame)\n",
    "    if cv2.waitKey(1)==27:\n",
    "        break\n",
    "\n",
    "stream.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56017698",
   "metadata": {},
   "source": [
    "### MTCNN face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b1ef5",
   "metadata": {
    "id": "3c4b1ef5"
   },
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "import cv2, os\n",
    "\n",
    "username = 'user'\n",
    "path = 'faces/'+username\n",
    "count=0\n",
    "n_of_images=100\n",
    "while os.path.isdir(path):\n",
    "    count+=1\n",
    "    path='faces/'+username+str(count)  \n",
    "os.makedirs(path)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "i,j = 0,0\n",
    "while 1:\n",
    "    _,frame = cap.read()\n",
    "    detector = MTCNN()\n",
    "    r = detector.detect_faces(frame)\n",
    "    if r==[]:\n",
    "        continue\n",
    "    faces = r[0]['box']\n",
    "    (x,y,w,h) = faces\n",
    "    cv2.putText(frame,f'Images Captured: {i}/{n_of_images}',(30,30),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255, 0, 20),1,cv2.LINE_AA)\n",
    "    name = str(i)+'.jpg'\n",
    "#     cv2.imwrite(path+'/'+name,frame[y:y+h,x:x+w])\n",
    "    cv2.imwrite(path+'/'+name,frame)\n",
    "    cv2.rectangle(frame,(x, y), (x+w, y+h), (255, 0, 20), 2)\n",
    "    i+=1\n",
    "    if i==n_of_images:\n",
    "        break\n",
    "    cv2.imshow('Adding new User',frame)\n",
    "    if cv2.waitKey(1)==27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdfae64f",
   "metadata": {},
   "source": [
    "### pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1418a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class_dictionary = train_generator.class_indices\n",
    "\n",
    "with open('emp-face-labels.pickle',\"rb\") as f:\n",
    "    obj = pickle.load(f)\n",
    "    print(len(obj), obj)\n",
    "    \n",
    "    for key, value in class_dictionary.items():\n",
    "        obj[value+len(obj)]=key\n",
    "    print(obj)\n",
    "        \n",
    "with open(\"emp-face-labels.pickle\",\"wb\") as f:\n",
    "    pickle.dump(obj, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
