{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d095cc8",
   "metadata": {
    "id": "8d095cc8"
   },
   "source": [
    "## YUNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5032e5",
   "metadata": {
    "id": "7d5032e5"
   },
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "detector = cv2.FaceDetectorYN.create(\"yunet_22mar.onnx\", \"\", (320, 320))\n",
    "i=0\n",
    "j=0\n",
    "n_images=500\n",
    "k=int(n_images/10)\n",
    "s=dt.now()\n",
    "while True:\n",
    "    ret, collection_frame = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    height, width, _ = collection_frame.shape\n",
    "    detector.setInputSize((width, height))\n",
    "    _, faces = detector.detect(collection_frame)\n",
    "    if faces is not None:\n",
    "        for face in faces:\n",
    "#             if i%10==0:\n",
    "#                 j+=1\n",
    "            x,y,w,h = list(map(int, face[:4]))\n",
    "            cv2.putText(collection_frame, f'Images Captured: {j}/{k}',(30,30),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255, 127, 0),1,cv2.LINE_AA)\n",
    "            cv2.rectangle(collection_frame, (x,y), (x+w,y+h), (255,0,0), 2)   \n",
    "\n",
    "#     i+=1\n",
    "    cv2.imshow('img', collection_frame)\n",
    "    if i==n_images:\n",
    "        break\n",
    "    if cv2.waitKey(1)==27:\n",
    "        break\n",
    "\n",
    "e=dt.now()\n",
    "t=e-s\n",
    "print(t.total_seconds())\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bea82c14",
   "metadata": {
    "id": "bea82c14"
   },
   "source": [
    "## VGGFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b37496",
   "metadata": {
    "collapsed": true,
    "id": "95b37496"
   },
   "outputs": [],
   "source": [
    "# !pip install keras_vggface\n",
    "# !pip install tensorflow\n",
    "# !pip install keras_applications\n",
    "# !pip install opencv-python\n",
    "# !pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b543237",
   "metadata": {
    "id": "8b543237"
   },
   "outputs": [],
   "source": [
    "# change - from keras.engine.topology import get_source_inputs\n",
    "# to - from keras.utils.layer_utils import get_source_inputs\n",
    "# in keras vggface, model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba49fe2",
   "metadata": {
    "id": "9ba49fe2"
   },
   "outputs": [],
   "source": [
    "# model = VGGFace(model='senet50')\n",
    "# model = VGGFace(model='resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c02362",
   "metadata": {
    "id": "37c02362"
   },
   "outputs": [],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "model = VGGFace(model='vgg16')\n",
    "model = VGGFace()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31b1bc7d",
   "metadata": {
    "id": "31b1bc7d"
   },
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02786387",
   "metadata": {
    "id": "02786387",
    "outputId": "ca0c90e3-a12c-4f9c-cfc7-9a864c57f11d"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "headshots_folder_name = 'dataset'\n",
    "\n",
    "# dimension of images\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "# for detecting faces\n",
    "facecascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# set the directory containing the images\n",
    "images_dir = os.path.join(\".\", headshots_folder_name)\n",
    "\n",
    "current_id = 0\n",
    "label_ids = {}\n",
    "\n",
    "# iterates through all the files in each subdirectories\n",
    "for root, _, files in os.walk(images_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\") or file.endswith(\"jpeg\"):\n",
    "            path = os.path.join(root, file)\n",
    "\n",
    "            # get the label name (name of the person)\n",
    "            label = os.path.basename(root).replace(\" \", \".\").lower()\n",
    "\n",
    "            # add the label (key) and its number (value)\n",
    "            if not label in label_ids:\n",
    "                label_ids[label] = current_id\n",
    "                current_id += 1\n",
    "\n",
    "            # load the image\n",
    "            imgtest = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "            image_array = np.array(imgtest, \"uint8\")\n",
    "\n",
    "            # get the faces detected in the image\n",
    "            faces = facecascade.detectMultiScale(imgtest, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "            # if not exactly 1 face is detected, skip this photo\n",
    "            if len(faces) != 1:\n",
    "                print(f'---Photo skipped---\\n')\n",
    "                os.remove(path)\n",
    "                continue\n",
    "\n",
    "            # save the detected face(s) and associate\n",
    "            # them with the label\n",
    "            for (x_, y_, w, h) in faces:\n",
    "\n",
    "                # draw the face detected\n",
    "                face_detect = cv2.rectangle(imgtest,\n",
    "                        (x_, y_),\n",
    "                        (x_+w, y_+h),\n",
    "                        (255, 0, 255), 2)\n",
    "                \n",
    "                plt.imshow(face_detect)\n",
    "                plt.show()\n",
    "\n",
    "                # resize the detected face to 224x224\n",
    "                size = (image_width, image_height)\n",
    "\n",
    "                # detected face region\n",
    "                roi = image_array[y_: y_ + h, x_: x_ + w]\n",
    "\n",
    "                # resize the detected head to target size\n",
    "                resized_image = cv2.resize(roi, size)\n",
    "                image_array = np.array(resized_image, \"uint8\")\n",
    "\n",
    "                # remove the original image\n",
    "                os.remove(path)\n",
    "\n",
    "                # replace the image with only the face\n",
    "                im = Image.fromarray(image_array)\n",
    "                im.save(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffc78097",
   "metadata": {
    "id": "ffc78097"
   },
   "source": [
    "# TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691c1fe",
   "metadata": {
    "id": "5691c1fe"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cacc8",
   "metadata": {
    "id": "892cacc8",
    "outputId": "25c04df3-a58c-4263-d6b1-69cca0e06f3a"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "'./dataset',\n",
    "target_size=(224,224),\n",
    "color_mode='rgb',\n",
    "batch_size=32,\n",
    "class_mode='categorical',\n",
    "shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6083954e",
   "metadata": {
    "id": "6083954e"
   },
   "outputs": [],
   "source": [
    "train_generator.class_indices.values()\n",
    "\n",
    "NO_CLASSES = len(train_generator.class_indices.values()) #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186ddf5f",
   "metadata": {
    "id": "186ddf5f",
    "outputId": "f2b74feb-8a5a-49da-adf0-6f92941c91fb"
   },
   "outputs": [],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "base_model = VGGFace(include_top=True,\n",
    "            model='vgg16',\n",
    "            input_shape=(224, 224, 3))\n",
    "\n",
    "base_model.summary()\n",
    "print(len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2e474",
   "metadata": {
    "id": "cbd2e474",
    "outputId": "a5d6cdb2-a6c7-4173-c210-204d3088e6fe"
   },
   "outputs": [],
   "source": [
    "base_model = VGGFace(include_top=False,\n",
    "                    model='vgg16',\n",
    "                    input_shape=(224, 224, 3))\n",
    "base_model.summary()\n",
    "print(len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345647d4",
   "metadata": {
    "id": "345647d4"
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "preds = Dense(NO_CLASSES, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5d248",
   "metadata": {
    "id": "21f5d248",
    "outputId": "d3fc4662-0067-46e6-dea4-84f081331d98"
   },
   "outputs": [],
   "source": [
    "model = Model(inputs = base_model.input, outputs = preds)\n",
    "model.summary()\n",
    "\n",
    "for layer in model.layers[:19]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in model.layers[19:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5727084",
   "metadata": {
    "id": "b5727084"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        optimizer='Adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d17433",
   "metadata": {
    "id": "19d17433",
    "outputId": "d4027493-ca3f-49b8-b094-fec27262f313"
   },
   "outputs": [],
   "source": [
    "model.fit(train_generator,\n",
    "          batch_size = 1,\n",
    "          verbose = 1,\n",
    "          epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a699537",
   "metadata": {
    "id": "5a699537"
   },
   "outputs": [],
   "source": [
    "model.save('emp_face_vgg_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9074e82",
   "metadata": {
    "id": "f9074e82"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('emp_face_vgg_model.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfece77",
   "metadata": {
    "id": "bbfece77",
    "outputId": "98f7cd6e-4016-44b9-cbb3-84fec69c8c1f"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class_dictionary = train_generator.class_indices\n",
    "class_dictionary = {value:key for key, value in class_dictionary.items()}\n",
    "print(class_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538c5103",
   "metadata": {
    "id": "538c5103"
   },
   "outputs": [],
   "source": [
    "face_label_filename = 'emp-face-labels.pickle'\n",
    "with open(face_label_filename, 'wb') as f: \n",
    "    pickle.dump(class_dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01de4d4",
   "metadata": {
    "id": "e01de4d4",
    "outputId": "9f6a7552-3725-433a-83a8-fd0f80014879"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "# from keras.preprocessing import image\n",
    "import keras.utils as image\n",
    "from keras_vggface import utils\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "face_label_filename = 'emp-face-labels.pickle'\n",
    "with open(face_label_filename, \"rb\") as \\\n",
    "    f: class_dictionary = pickle.load(f)\n",
    "\n",
    "class_list = [value for _, value in class_dictionary.items()]\n",
    "print(class_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f7f748a",
   "metadata": {
    "id": "3f7f748a"
   },
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ada74",
   "metadata": {
    "id": "bb0ada74",
    "outputId": "6f871f61-f25c-4424-a8bc-15f52f209335"
   },
   "outputs": [],
   "source": [
    "import keras.utils as image\n",
    "from datetime import datetime as dt\n",
    "\n",
    "s=dt.now()\n",
    "facecascade =  cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "model = load_model('emp_face_vgg_model.h5')\n",
    "test_image_filename = r'C:\\Users\\seema1\\Desktop\\facenet,vggface\\x.jpeg'\n",
    "imgtest = cv2.imread(test_image_filename, cv2.IMREAD_COLOR)\n",
    "image_array = np.array(imgtest, \"uint8\")\n",
    "faces = facecascade.detectMultiScale(imgtest, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "if len(faces) == 1:    \n",
    "    for (x_, y_, w, h) in faces:\n",
    "        face_detect = cv2.rectangle(imgtest, (x_, y_), (x_+w, y_+h), (255, 0, 255), 2)\n",
    "        plt.imshow(face_detect)\n",
    "        plt.show()\n",
    "\n",
    "        size = (image_width, image_height)\n",
    "        roi = image_array[y_: y_ + h, x_: x_ + w]\n",
    "        resized_image = cv2.resize(roi, size)\n",
    "\n",
    "        x = image.img_to_array(resized_image)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = utils.preprocess_input(x, version=1)\n",
    "      \n",
    "        predicted_prob = model.predict(x)\n",
    "        print(predicted_prob)\n",
    "        print(predicted_prob[0].argmax())\n",
    "        print(\"Predicted face: \" + class_list[predicted_prob[0].argmax()])\n",
    "\n",
    "e=dt.now()        \n",
    "print('time: ', (e-s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a64626b",
   "metadata": {
    "id": "9a64626b"
   },
   "source": [
    "## REAL TIME INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d997968c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec3159d",
   "metadata": {
    "id": "9ec3159d",
    "outputId": "51ab5924-8452-4182-c94d-bf15b8f01cce",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    image_width = 224\n",
    "    image_height = 224\n",
    "\n",
    "    detector = cv2.FaceDetectorYN.create(\"yunet_22mar.onnx\", \"\", (320, 320))\n",
    "    model = load_model('emp_face_vgg_model.h5', compile=False)\n",
    "    with open(\"emp-face-labels.pickle\", 'rb') as f:\n",
    "        og_labels = pickle.load(f)\n",
    "        labels = {key:value for key,value in og_labels.items()}\n",
    "\n",
    "    stream = cv2.VideoCapture(0)\n",
    "    while(True):\n",
    "        (grabbed, frame) = stream.read()\n",
    "        height, width, _ = frame.shape\n",
    "        detector.setInputSize((width, height))\n",
    "        _, faces = detector.detect(frame)\n",
    "        if faces is not None:    \n",
    "            for face in faces:\n",
    "                x,y,w,h = list(map(int, face[:4]))\n",
    "\n",
    "                color = (255, 127, 0)\n",
    "                stroke = 2\n",
    "                cv2.rectangle(frame, (x,y), (x+w,y+h), color, stroke)\n",
    "\n",
    "                roi_rgb = frame[y:y+h, x:x+w]\n",
    "                size = (image_width, image_height)\n",
    "                resized_image = cv2.resize(roi_rgb, size)\n",
    "                image_array = np.array(resized_image, \"uint8\")\n",
    "                img = image_array.reshape(1,image_width,image_height,3) \n",
    "                img = img.astype('float32')\n",
    "                img /= 255\n",
    "                predicted_prob = model.predict(img)\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                name = labels[predicted_prob[0].argmax()]\n",
    "                color = (255, 0, 255)\n",
    "                stroke = 2\n",
    "                cv2.putText(frame, f'({name})', (x,y-8), font, 1, color, stroke, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        cv2.imshow(\"Image\", frame)\n",
    "        if cv2.waitKey(1)==27:\n",
    "            break\n",
    "\n",
    "    stream.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37b1f656",
   "metadata": {
    "id": "3c4b1ef5"
   },
   "source": [
    "### exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2892d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/GPU:0'):\n",
    "image_width = 224\n",
    "image_height = 224\n",
    "\n",
    "detector = cv2.FaceDetectorYN.create(\"yunet_22mar.onnx\", \"\", (320, 320))\n",
    "model = load_model('model.h5')\n",
    "with open(\"labels.pickle\", 'rb') as f:\n",
    "    og_labels = pickle.load(f)\n",
    "    labels = {key:value for key,value in og_labels.items()}\n",
    "    \n",
    "c=0\n",
    "\n",
    "stream = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    (grabbed, frame) = stream.read()\n",
    "    if frame is None:\n",
    "        continue\n",
    "\n",
    "    height, width, _ = frame.shape\n",
    "    detector.setInputSize((width, height))\n",
    "    _, faces = detector.detect(frame)\n",
    "    if faces is not None:    \n",
    "        for face in faces:\n",
    "            x,y,w,h = list(map(int, face[:4]))\n",
    "\n",
    "            color = (255, 127, 0)\n",
    "            stroke = 2\n",
    "            cv2.rectangle(frame, (x,y), (x+w,y+h), color, stroke)\n",
    "\n",
    "            try:\n",
    "                roi_rgb = frame[y:y+h, x:x+w]\n",
    "                size = (image_width, image_height)\n",
    "                resized_image = cv2.resize(roi_rgb, size)\n",
    "                image_array = np.array(resized_image, \"uint8\")\n",
    "                img = image_array.reshape(1,image_width,image_height,3) \n",
    "                img = img.astype('float32')\n",
    "                img /= 255\n",
    "                predicted_prob = model.predict(img)\n",
    "                print(predicted_prob)\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                print(predicted_prob[0].argmax())\n",
    "                \n",
    "                name = labels[predicted_prob[0].argmax()]\n",
    "                print(name)\n",
    "                \n",
    "                color = (255, 0, 255)\n",
    "                stroke = 2\n",
    "                cv2.putText(frame, f'({name})', (x,y-8), font, 1, color, stroke, cv2.LINE_AA)\n",
    "                c+=1\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    cv2.imshow(\"Image\", frame)\n",
    "    if c==2 or cv2.waitKey(1)==27:\n",
    "        break\n",
    "\n",
    "stream.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
