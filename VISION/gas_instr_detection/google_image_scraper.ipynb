{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15fcf33",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "837bfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import WebDriverException, SessionNotCreatedException\n",
    "import sys\n",
    "import os\n",
    "import urllib.request\n",
    "import re\n",
    "import zipfile\n",
    "import stat\n",
    "from sys import platform\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "import time\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "import re\n",
    "import concurrent.futures\n",
    "\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "from PIL import Image\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c64d1",
   "metadata": {},
   "source": [
    "# GIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79e9bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleImageScraper():\n",
    "    def __init__(self, image_path, search_key=\"cat\", number_of_images=1, headless=True, min_resolution=(0, 0), max_resolution=(1920, 1080), max_missed=10):\n",
    "        image_path = os.path.join(image_path, search_key)\n",
    "        if (type(number_of_images)!=int):\n",
    "            print(\"[Error] Number of images must be integer value.\")\n",
    "            return\n",
    "        if not os.path.exists(image_path):\n",
    "            print(\"[INFO] Image path not found. Creating a new folder.\")\n",
    "            os.makedirs(image_path)\n",
    "\n",
    "        for i in range(1):\n",
    "            try:\n",
    "                options = webdriver.ChromeOptions()\n",
    "                ser = Service(r\"webdriver/chromedriver.exe\")\n",
    "                options.add_argument(\"--no-sandbox\")\n",
    "                options.add_argument(\"--disable-dev-shm-usage\")\n",
    "                if(headless):\n",
    "                    options.add_argument('--headless')\n",
    "                driver = webdriver.Chrome(service=ser, chrome_options=options)\n",
    "                driver.set_window_size(1400,1050)\n",
    "                driver.get(\"https://www.google.com\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        self.driver = driver\n",
    "        self.search_key = search_key\n",
    "        self.number_of_images = number_of_images\n",
    "        self.webdriver_path = webdriver_path\n",
    "        self.image_path = image_path\n",
    "        self.url = \"https://www.google.com/search?q=%s&source=lnms&tbm=isch&sa=X&ved=2ahUKEwie44_AnqLpAhUhBWMBHUFGD90Q_AUoAXoECBUQAw&biw=1920&bih=947\"%(search_key)\n",
    "        self.headless=headless\n",
    "        self.min_resolution = min_resolution\n",
    "        self.max_resolution = max_resolution\n",
    "        self.max_missed = max_missed\n",
    "\n",
    "    def find_image_urls(self):\n",
    "        \"\"\"\n",
    "            This function search and return a list of image urls based on the search key.\n",
    "            Example:\n",
    "                google_image_scraper = GoogleImageScraper(\"webdriver_path\",\"image_path\",\"search_key\",number_of_photos)\n",
    "                image_urls = google_image_scraper.find_image_urls()\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Gathering image links\")\n",
    "        self.driver.get(self.url)\n",
    "        image_urls=[]\n",
    "        count = 0\n",
    "        missed_count = 0\n",
    "        indx_1 = 0\n",
    "        indx_2 = 0\n",
    "        search_string = '//*[@id=\"islrg\"]/div[1]/div[%s]/a[1]/div[1]/img'\n",
    "        time.sleep(3)\n",
    "        while self.number_of_images > count and missed_count < self.max_missed:\n",
    "            if indx_2 > 0:\n",
    "                try:\n",
    "                    imgurl = self.driver.find_element(By.XPATH, search_string%(indx_1,indx_2+1))\n",
    "                    imgurl.click()\n",
    "                    indx_2 = indx_2 + 1\n",
    "                    missed_count = 0\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        imgurl = self.driver.find_element(By.XPATH, search_string%(indx_1+1,1))\n",
    "                        imgurl.click()\n",
    "                        indx_2 = 1\n",
    "                        indx_1 = indx_1 + 1\n",
    "                    except:\n",
    "                        indx_2 = indx_2 + 1\n",
    "                        missed_count = missed_count + 1\n",
    "            else:\n",
    "                try:\n",
    "                    imgurl = self.driver.find_element(By.XPATH, search_string%(indx_1+1))\n",
    "                    imgurl.click()\n",
    "                    missed_count = 0\n",
    "                    indx_1 = indx_1 + 1    \n",
    "                except Exception:\n",
    "                    try:\n",
    "                        imgurl = self.driver.find_element(By.XPATH, '//*[@id=\"islrg\"]/div[1]/div[%s]/div[%s]/a[1]/div[1]/img'%(indx_1,indx_2+1))\n",
    "                        imgurl.click()\n",
    "                        missed_count = 0\n",
    "                        indx_2 = indx_2 + 1\n",
    "                        search_string = '//*[@id=\"islrg\"]/div[1]/div[%s]/div[%s]/a[1]/div[1]/img'\n",
    "                    except Exception:\n",
    "                        indx_1 = indx_1 + 1\n",
    "                        missed_count = missed_count + 1\n",
    "                    \n",
    "            try:\n",
    "                #select image from the popup\n",
    "                time.sleep(1)\n",
    "                class_names = [\"n3VNCb\",\"iPVvYb\",\"r48jcc\",\"pT0Scc\"]\n",
    "                images = [self.driver.find_elements(By.CLASS_NAME, class_name) for class_name in class_names if len(self.driver.find_elements(By.CLASS_NAME, class_name)) != 0 ][0]\n",
    "                for image in images:\n",
    "                    #only download images that starts with http\n",
    "                    src_link = image.get_attribute(\"src\")\n",
    "                    if((\"http\" in src_link) and (not \"encrypted\" in src_link)):\n",
    "                        print(\n",
    "                            f\"[INFO] {self.search_key} \\t #{count} \\t {src_link}\")\n",
    "                        image_urls.append(src_link)\n",
    "                        print(image_urls)\n",
    "                        count +=1\n",
    "                        break\n",
    "            except Exception:\n",
    "                print(\"[INFO] Unable to get link\")\n",
    "\n",
    "            try:\n",
    "                #scroll page to load next image\n",
    "                if(count%3==0):\n",
    "                    self.driver.execute_script(\"window.scrollTo(0, \"+str(indx_1*60)+\");\")\n",
    "                element = self.driver.find_element(By.CLASS_NAME,\"mye4qd\")\n",
    "                element.click()\n",
    "                print(\"[INFO] Loading next page\")\n",
    "                time.sleep(3)\n",
    "            except Exception:\n",
    "                time.sleep(1)\n",
    "\n",
    "        self.driver.quit()\n",
    "        print(\"[INFO] Google search ended\")\n",
    "        return image_urls\n",
    "\n",
    "    def save_images(self,image_urls, keep_filenames):\n",
    "        print(keep_filenames)\n",
    "        #save images into file directory\n",
    "        \"\"\"\n",
    "            This function takes in an array of image urls and save it into the given image path/directory.\n",
    "            Example:\n",
    "                google_image_scraper = GoogleImageScraper(\"webdriver_path\",\"image_path\",\"search_key\",number_of_photos)\n",
    "                image_urls=[\"https://example_1.jpg\",\"https://example_2.jpg\"]\n",
    "                google_image_scraper.save_images(image_urls)\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Saving image, please wait...\")\n",
    "        for indx,image_url in enumerate(image_urls):\n",
    "            try:\n",
    "                print(\"[INFO] Image url:%s\"%(image_url))\n",
    "                search_string = ''.join(e for e in self.search_key if e.isalnum())\n",
    "                image = requests.get(image_url,timeout=5)\n",
    "                if image.status_code == 200:\n",
    "                    with Image.open(io.BytesIO(image.content)) as image_from_web:\n",
    "                        try:\n",
    "                            if (keep_filenames):\n",
    "                                #extact filename without extension from URL\n",
    "                                o = urlparse(image_url)\n",
    "                                image_url = o.scheme + \"://\" + o.netloc + o.path\n",
    "                                name = os.path.splitext(os.path.basename(image_url))[0]\n",
    "                                #join filename and extension\n",
    "                                filename = \"%s.%s\"%(name,image_from_web.format.lower())\n",
    "                            else:\n",
    "                                filename = \"%s%s.%s\"%(search_string,str(indx),image_from_web.format.lower())\n",
    "\n",
    "                            image_path = os.path.join(self.image_path, filename)\n",
    "                            print(\n",
    "                                f\"[INFO] {self.search_key} \\t {indx} \\t Image saved at: {image_path}\")\n",
    "                            image_from_web.save(image_path)\n",
    "                        except OSError:\n",
    "                            rgb_im = image_from_web.convert('RGB')\n",
    "                            rgb_im.save(image_path)\n",
    "                        image_resolution = image_from_web.size\n",
    "                        if image_resolution != None:\n",
    "                            if image_resolution[0]<self.min_resolution[0] or image_resolution[1]<self.min_resolution[1] or image_resolution[0]>self.max_resolution[0] or image_resolution[1]>self.max_resolution[1]:\n",
    "                                image_from_web.close()\n",
    "                                os.remove(image_path)\n",
    "\n",
    "                        image_from_web.close()\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(\"[ERROR] Download failed: \",e)\n",
    "                pass\n",
    "            \n",
    "            print(\"[INFO] Downloads completed. Please note that some photos were not downloaded as they were not in the correct format (e.g. jpg, jpeg, png)\")\n",
    "            print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0329d3c0",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11e54f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_thread(search_key):\n",
    "    image_scraper = GoogleImageScraper(\n",
    "        image_path, \n",
    "        search_key, \n",
    "        number_of_images, \n",
    "        headless, \n",
    "        min_resolution, \n",
    "        max_resolution, \n",
    "        max_missed)\n",
    "    \n",
    "    image_urls = image_scraper.find_image_urls()\n",
    "    image_scraper.save_images(image_urls, keep_filenames)\n",
    "\n",
    "    del image_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "557753de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Image path not found. Creating a new folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seema1\\AppData\\Local\\Temp\\ipykernel_9472\\1517175601.py:19: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(service=ser, chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Image path not found. Creating a new folder.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    image_path = os.path.normpath(os.path.join(os.getcwd(), 'GoogleImageScrapper_photos'))\n",
    "    search_keys = list(set([\"gas distribution valve\", \"gas distribution meter\"]))\n",
    "\n",
    "    #Parameters\n",
    "    number_of_images = 100                # Desired number of images\n",
    "    headless = False                     # True = No Chrome GUI\n",
    "    min_resolution = (0, 0)             # Minimum desired image resolution\n",
    "    max_resolution = (9999, 9999)       # Maximum desired image resolution\n",
    "    max_missed = 100                     # Max number of failed images before exit\n",
    "    number_of_workers = 1               # Number of \"workers\" used\n",
    "    keep_filenames = False              # Keep original URL image filenames\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=number_of_workers) as executor:\n",
    "        executor.map(worker_thread, search_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8b189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f7796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
